{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrRJFfY31IeNzFwjdx22ZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suelen-prs/EBAC/blob/main/Exercicio2_Modulo24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações necessárias\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "26HVBz5VWoK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Cite 5 diferenças entre o RandomForest e o AdaBoost os do exemplo (load_iris)"
      ],
      "metadata": {
        "id": "X69ugGhaVX3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Método de Construção:** RandomForest constrói várias árvores de decisão independentemente usando amostras de bootstrap dos dados. AdaBoost constrói modelos sequencialmente, onde cada modelo subsequente tenta corrigir os erros do anterior.\n",
        "\n",
        "**Ponderação das Previsões:** No RandomForest, todas as árvores contribuem igualmente para a previsão final. No AdaBoost, modelos subsequentes recebem pesos baseados na precisão dos modelos anteriores, com modelos mais precisos tendo maior influência.\n",
        "\n",
        "**Tratamento de Erros:** RandomForest trata erros reduzindo a variância através do ensemble de árvores. AdaBoost foca na redução de bias (viés), dando mais peso aos exemplos que foram classificados incorretamente.\n",
        "\n",
        "**Seleção de Atributos:** No treinamento de RandomForest, um subconjunto aleatório de atributos é considerado para cada divisão. No AdaBoost, todos os atributos estão disponíveis para cada modelo na sequência.\n",
        "\n",
        "**Complexidade e Overfitting:** RandomForest é geralmente robusto contra overfitting, especialmente quando o número de árvores é grande. AdaBoost pode ser mais suscetível a overfitting, especialmente em dados com ruído."
      ],
      "metadata": {
        "id": "q8wCSwTJV4sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Acesse o link Scikit-learn–adaboost, leia a explicação (traduza se for preciso) e crie um jupyternotebook contendo o exemplo do AdaBoost."
      ],
      "metadata": {
        "id": "l6G4QiydVacq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o conjunto de dados\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Instanciar o modelo AdaBoost\n",
        "ada_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "# Treinar o modelo\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "# Avaliar o modelo\n",
        "print(f\"Score de Treinamento: {ada_clf.score(X_train, y_train)}\")\n",
        "print(f\"Score de Teste: {ada_clf.score(X_test, y_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwY0wvi7WFXl",
        "outputId": "dcaad1a9-60db-4bb8-b7c7-12c742c3d942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score de Treinamento: 0.9666666666666667\n",
            "Score de Teste: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Cite 5 Hyperparametrosimportantes no AdaBoost."
      ],
      "metadata": {
        "id": "OdnSqZuxVdmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n_estimators:** Número de modelos sequenciais a serem incluídos no ensemble.\n",
        "\n",
        "**learning_rate:** Peso aplicado a cada classificador em cada iteração de boosting.\n",
        "\n",
        "**base_estimator:** O modelo base utilizado para o processo de boosting, com um DecisionTreeClassifier de profundidade 1 como padrão.\n",
        "\n",
        "**algorithm:** O algoritmo de boosting a ser usado, SAMME ou SAMME.R.\n",
        "\n",
        "**random_state:** Controla a aleatoriedade do processo de seleção das amostras, garantindo resultados reproduzíveis"
      ],
      "metadata": {
        "id": "rjjBS3WNWMII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. (Opcional) Utilize o GridSearchpara encontrar os melhores hyperparametrospara o conjunto de dados do exemplo (load_iris)"
      ],
      "metadata": {
        "id": "ysA5sTiFVg8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o conjunto de dados e dividir\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Configurar o espaço de hiperparâmetros para testar\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "# Instanciar o modelo AdaBoost com um classificador base\n",
        "ada_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), random_state=42)\n",
        "\n",
        "# Instanciar e executar o GridSearch\n",
        "grid_search = GridSearchCV(ada_clf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhores parâmetros e score\n",
        "print(f\"Melhores Parâmetros: {grid_search.best_params_}\")\n",
        "print(f\"Melhor Score de Cross-Validation: {grid_search.best_score_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqZl0qJcWY5A",
        "outputId": "4e8877a5-4895-4557-cce4-8a3c3b7b5590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores Parâmetros: {'learning_rate': 1, 'n_estimators': 200}\n",
            "Melhor Score de Cross-Validation: 0.9416666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Acessando o artigo do Jerome Friedman (Stochastic) e pensando no nome dado ao Stochastic GBM, qual é a maior diferença entre os dois algoritmos?"
      ],
      "metadata": {
        "id": "wrV9AZnpdUYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A maior diferença entre o Gradient Boosting Machine (GBM) tradicional e o Stochastic Gradient Boosting Machine (SGBM), conforme introduzido por Jerome Friedman, reside no processo de amostragem utilizado durante o treinamento das árvores.\n",
        "\n",
        "No GBM tradicional, todas as árvores são treinadas usando todo o conjunto de dados de treinamento. Cada árvore tenta corrigir os erros da árvore anterior, focando nas instâncias mais difíceis de prever corretamente.\n",
        "\n",
        "No Stochastic Gradient Boosting Machine (SGBM), por outro lado, cada árvore é treinada em uma amostra aleatória do conjunto de dados de treinamento. Esta amostra é tirada com reposição (bootstrap sample), semelhante ao que é feito no Bagging. A principal diferença é que, em vez de construir árvores em paralelo como no Bagging, o SGBM constrói as árvores sequencialmente, onde cada nova árvore é construída para corrigir os erros deixados pelas árvores anteriores.\n",
        "\n",
        "Essa abordagem estocástica introduz mais diversidade nas árvores construídas, o que pode ajudar a reduzir o risco de overfitting e melhorar a generalização do modelo em dados não vistos. Além disso, treinar em subconjuntos dos dados torna o processo mais eficiente computacionalmente, permitindo que o SGBM lidere com grandes conjuntos de dados de forma mais eficaz."
      ],
      "metadata": {
        "id": "SJ4TyTlmdfx1"
      }
    }
  ]
}